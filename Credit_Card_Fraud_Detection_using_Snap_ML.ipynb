{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installing SnapMl library\n",
    "\n",
    "##### we are going to use python API which is offered by Snap Machin Learning. SnapMl is a hig performance library from IBM. It provides highly efficient CPU/GPU implementation of linear model and tree based model. Here we are going to use a Decision tree and Support Vector Machine models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data set\n",
    "\n",
    "##### For this detection i am going to use the real data set and which is includes information about transactions made by credit cards in September 2013 by European cardholders. In the data set each row represent a credit card transactions and the class columns is a target column which we have to predict. This data set is highly unbalanced and the target variable is not equally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30234ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snapml in c:\\users\\rsibr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.14.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rsibr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snapml) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rsibr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snapml) (1.11.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\rsibr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snapml) (1.25.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rsibr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->snapml) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rsibr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->snapml) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install snapml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # To work with DataFrame and open the file\n",
    "import numpy as np # For a Array level calculation or working with array\n",
    "import matplotlib.pyplot as plt # Visualize the results\n",
    "from sklearn.model_selection import train_test_split as tts# use to split the training set and train the model\n",
    "from sklearn.preprocessing import StandardScaler as sds,normalize as norm # Use to preprocess the raw data and eliminate the unwanted datas\n",
    "from sklearn.utils.class_weight import compute_class_weight as ccw # Used to handel the imbalanced data\n",
    "from sklearn.metrics import roc_auc_score as ras # a popular metric for evaluating the performance of classification models, \n",
    "# particularly in binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_dataset = pd.read_csv(\"creditcard.csv\") \n",
    "cc_dataset.head() # Print the first 5 rows from the dataset\n",
    "cc_dataset.shape # check the raws and columns (diamention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To deal Big data we can make the data set 10 times bigger than it was exist. becouse in prectically the financial institude may have acces for much larger data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "2    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "3    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "4    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "5    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "6    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "7    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "8    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "9    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "10   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "\n",
       "          V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "2   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "3   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "4   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "5   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "6   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "7   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "8   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "9   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "10 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "\n",
       "         V25       V26       V27       V28  Amount  Class  \n",
       "0   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "2   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "3   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "4   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "5   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "6   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "7   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "8   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "9   0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "10  0.167170  0.125895 -0.008983  0.014724    2.69    0.0  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_replication = 10\n",
    "\n",
    "big_cc_dataset = pd.DataFrame(np.repeat(cc_dataset.values,n_replication,axis=0),columns=cc_dataset.columns)\n",
    "# pd.DataFrame is used to change the array into DataFrame\n",
    "# np.repeat is used to repeat the values from the data n_replication time in the axis = 0 and change them to array\n",
    "# This data extension is known as inflation\n",
    "big_cc_dataset.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse the target variable value with respect to other columns value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0.0    2843150\n",
       "1.0       4920\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_variable = big_cc_dataset.Class.unique() \n",
    "#.unique() function used to get a distinct value\n",
    "# Here the target variable has only 0 and 1 so it would be a binery classification problem\n",
    "\n",
    "sizes = big_cc_dataset.Class.value_counts() \n",
    "# will give the count of transactions {1(Fraud) and 0(legit)}\n",
    "\n",
    "sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "#### We actually make mean and std equal for all the feature's  which is known as Standardizing and prepare the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (2848070, 29) Y_shape: (2848070,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "big_cc_dataset.iloc[:,1:30] = sds().fit_transform(big_cc_dataset.iloc[:,1:30])\n",
    "# Here i actually did is make all the feature's std 1 and mean 0 (excluding target variable) \n",
    "# using StandardScaler() function from sklearn and the fit it to all the features set and transform it\n",
    "\n",
    "big_cc_dataset_matrix = big_cc_dataset.values\n",
    "# In common method is to change the data set into numpy array before feeding to machine learning model\n",
    "# becouse we are going to work with sklean library\n",
    "\n",
    "X=big_cc_dataset_matrix[:,1:30]\n",
    "Y=big_cc_dataset_matrix[:,30] \n",
    "# Now select the X(Feature set) and Y(Target set)\n",
    "\n",
    "X=norm(X,norm=\"l1\") \n",
    "# Now i have to normalize() the feature set X to do this i am going to use L1 normalization\n",
    "# i am going to use this to ensure each row of the feature sets has a unit norm and sum of the absolute valu is 1\n",
    "# it will scale each sample's feature so that the sum will be one\n",
    "\n",
    "print(\"X_shape:\",X.shape,\"Y_shape:\",Y.shape)\n",
    "# print the shape of the sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Train/Test split\n",
    "#### Now I have the prepocessed dataset so it is ready to biuld a classification model, before that we should split the  preprocessed dataset into two subset such as Tarining set(used to train the model) another one is test set(Evaluating the quality of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = tts(X,Y,test_size=0.3,random_state=42,stratify=Y)\n",
    "# I am going to use the Train/Test split model from sklearn library \n",
    "# test_size is used to split the 30% of the data for testing and rest is for train\n",
    "# random_state used to set the random seed for reproducibility. and it will give the same output for all time\n",
    "# stratify use to maintain the data distribution of classes in both training and testing. \n",
    "# It is usufull when we deal with a classification problem with unbalanced dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
